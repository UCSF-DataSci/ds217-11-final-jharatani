{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b3d469",
   "metadata": {},
   "source": [
    "# Q2: Data Cleaning\n",
    "\n",
    "**Phase 3:** Data Cleaning & Preprocessing  \n",
    "**Points: 9 points**\n",
    "\n",
    "**Focus:** Handle missing data, outliers, validate data types, remove duplicates.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 1 ([`11/demo/01_setup_exploration_cleaning.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/01_setup_exploration_cleaning.ipynb)), Phase 3. Also see Lecture 05 (data cleaning).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a377e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load data from Q1 (or directly from source)\n",
    "df_beach = pd.read_csv('data/beach_sensors.csv')\n",
    "# If you saved cleaned data from Q1, you can load it:\n",
    "# df = pd.read_csv('output/q1_exploration.csv')  # This won't work - load original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6b0ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Clean the dataset by handling missing data, outliers, validating data types, and removing duplicates.\n",
    "\n",
    "**Time Series Note:** For time series data, forward-fill (`ffill()`) is often appropriate for missing values since sensor readings are continuous. However, you may choose other strategies based on your analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q2_cleaned_data.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Cleaned dataset with same structure as original (same columns)\n",
    "**Requirements:**\n",
    "- Same columns as original dataset\n",
    "- Missing values handled (filled, dropped, or imputed)\n",
    "- Outliers handled (removed, capped, or transformed)\n",
    "- Data types validated and converted\n",
    "- Duplicates removed\n",
    "- **Sanity check:** Dataset should retain most rows after cleaning (at least 1,000 rows). If you're removing more than 50% of data, reconsider your strategy—imputation is usually preferable to dropping rows for this dataset.\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "### 2. `output/q2_cleaning_report.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Detailed report of cleaning operations\n",
    "**Required information:**\n",
    "- Rows before cleaning: [number]\n",
    "- Missing data handling method: [description]\n",
    "  - Which columns had missing data\n",
    "  - Method used (drop, forward-fill, impute, etc.)\n",
    "  - Number of values handled\n",
    "- Outlier handling: [description]\n",
    "  - Detection method (IQR, z-scores, domain knowledge)\n",
    "  - Which columns had outliers\n",
    "  - Method used (remove, cap, transform)\n",
    "  - Number of outliers handled\n",
    "- Duplicates removed: [number]\n",
    "- Data type conversions: [list any conversions]\n",
    "- Rows after cleaning: [number]\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "DATA CLEANING REPORT\n",
    "====================\n",
    "\n",
    "Rows before cleaning: 50000\n",
    "\n",
    "Missing Data Handling:\n",
    "- Water Temperature: 2500 missing values (5.0%)\n",
    "  Method: Forward-fill (time series appropriate)\n",
    "  Result: All missing values filled\n",
    "  \n",
    "- Air Temperature: 1500 missing values (3.0%)\n",
    "  Method: Forward-fill, then median imputation for remaining\n",
    "  Result: All missing values filled\n",
    "\n",
    "Outlier Handling:\n",
    "- Water Temperature: Detected 500 outliers using IQR method (3×IQR)\n",
    "  Method: Capped at bounds [Q1 - 3×IQR, Q3 + 3×IQR]\n",
    "  Bounds: [-5.2, 35.8]\n",
    "  Result: 500 values capped\n",
    "\n",
    "Duplicates Removed: 0\n",
    "\n",
    "Data Type Conversions:\n",
    "- Measurement Timestamp: Converted to datetime64[ns]\n",
    "\n",
    "Rows after cleaning: 50000\n",
    "```\n",
    "\n",
    "### 3. `output/q2_rows_cleaned.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Single integer number (total rows after cleaning)\n",
    "**Requirements:**\n",
    "- Only the number, no text, no labels\n",
    "- No whitespace before or after\n",
    "- Example: `50000`\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Missing data handling strategy chosen and implemented\n",
    "- [ ] Outliers detected and handled (IQR method, z-scores, or domain knowledge)\n",
    "- [ ] Data types validated and converted\n",
    "- [ ] Duplicates identified and removed\n",
    "- [ ] Cleaning decisions documented in report\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Handle missing data** - Choose appropriate strategy (drop, forward-fill, impute) based on data characteristics\n",
    "2. **Detect and handle outliers** - Use IQR method or z-scores; decide whether to remove, cap, or transform\n",
    "3. **Validate data types** - Ensure numeric and datetime columns are properly typed\n",
    "4. **Remove duplicates**\n",
    "5. **Document and save** - Write detailed cleaning report explaining your decisions\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Missing data:** Should you drop rows, impute values, or forward-fill? Consider: How much data is missing? Is it random or systematic? For time series, forward-fill is often appropriate.\n",
    "- **Outliers:** Are they errors or valid extreme values? Use IQR method or z-scores to detect, then decide: remove, cap, or transform. Document your reasoning.\n",
    "- **Data types:** Are numeric columns actually numeric? Are datetime columns properly formatted? Convert as needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q2, you should have:\n",
    "- [ ] Missing data handled\n",
    "- [ ] Outliers addressed\n",
    "- [ ] Data types validated\n",
    "- [ ] Duplicates removed\n",
    "- [ ] All 3 artifacts saved: `q2_cleaned_data.csv`, `q2_cleaning_report.txt`, `q2_rows_cleaned.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q3_data_wrangling.md` for Data Wrangling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8bad71e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Missing Values'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wet Bulb Temperature</th>\n",
       "      <td>75951</td>\n",
       "      <td>38.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rain Intensity</th>\n",
       "      <td>75951</td>\n",
       "      <td>38.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Rain</th>\n",
       "      <td>75951</td>\n",
       "      <td>38.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heading</th>\n",
       "      <td>75951</td>\n",
       "      <td>38.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precipitation Type</th>\n",
       "      <td>75951</td>\n",
       "      <td>38.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barometric Pressure</th>\n",
       "      <td>146</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Air Temperature</th>\n",
       "      <td>75</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Missing Count  Missing %\n",
       "Wet Bulb Temperature          75951      38.69\n",
       "Rain Intensity                75951      38.69\n",
       "Total Rain                    75951      38.69\n",
       "Heading                       75951      38.69\n",
       "Precipitation Type            75951      38.69\n",
       "Barometric Pressure             146       0.07\n",
       "Air Temperature                  75       0.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Name                   0\n",
      "Measurement Timestamp          0\n",
      "Air Temperature                0\n",
      "Wet Bulb Temperature           0\n",
      "Humidity                       0\n",
      "Rain Intensity                 0\n",
      "Interval Rain                  0\n",
      "Total Rain                     0\n",
      "Precipitation Type             0\n",
      "Wind Direction                 0\n",
      "Wind Speed                     0\n",
      "Maximum Wind Speed             0\n",
      "Barometric Pressure            0\n",
      "Solar Radiation                0\n",
      "Heading                        0\n",
      "Battery Life                   0\n",
      "Measurement Timestamp Label    0\n",
      "Measurement ID                 0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Outlier Detection'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>outlier_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air Temperature</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wet Bulb Temperature</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Humidity</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain Intensity</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interval Rain</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Total Rain</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Precipitation Type</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wind Direction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wind Speed</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Maximum Wind Speed</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Barometric Pressure</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Solar Radiation</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Heading</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Battery Life</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column_name  outlier_count\n",
       "0        Air Temperature            377\n",
       "1   Wet Bulb Temperature            387\n",
       "2               Humidity            185\n",
       "3         Rain Intensity            197\n",
       "4          Interval Rain            198\n",
       "5             Total Rain            126\n",
       "6     Precipitation Type              0\n",
       "7         Wind Direction              0\n",
       "8             Wind Speed            191\n",
       "9     Maximum Wind Speed            193\n",
       "10   Barometric Pressure            367\n",
       "11       Solar Radiation            223\n",
       "12               Heading              0\n",
       "13          Battery Life            275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 196321\n",
      "Rows removed: 2350\n",
      "Cleaned rows: 193971\n",
      "                                      dtype\n",
      "Station Name                         object\n",
      "Measurement Timestamp        datetime64[ns]\n",
      "Air Temperature                     float64\n",
      "Wet Bulb Temperature                float64\n",
      "Humidity                              int64\n",
      "Rain Intensity                      float64\n",
      "Interval Rain                       float64\n",
      "Total Rain                          float64\n",
      "Precipitation Type                  float64\n",
      "Wind Direction                        int64\n",
      "Wind Speed                          float64\n",
      "Maximum Wind Speed                  float64\n",
      "Barometric Pressure                 float64\n",
      "Solar Radiation                       int64\n",
      "Heading                             float64\n",
      "Battery Life                        float64\n",
      "Measurement Timestamp Label          object\n",
      "Measurement ID                       object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Duplicate Detection'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'**Completely duplicate rows:** 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Missing Data by column\n",
    "display(\"# Missing Values\")\n",
    "\n",
    "missing = df_beach.isnull().sum()\n",
    "missing_pct = (missing / len(df_beach)) *100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count' : missing, \n",
    "    'Missing %': missing_pct.round(2)\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) == 0:\n",
    "    display(\"**No missing values found!**\")\n",
    "else:\n",
    "    display(missing_df)\n",
    "\n",
    "cols_missing = [\"Wet Bulb Temperature\",\"Rain Intensity\",\"Total Rain\",\"Heading\",\"Precipitation Type\",\"Barometric Pressure\",\"Air Temperature\"]\n",
    "\n",
    "df_beach[cols_missing] = df_beach[cols_missing].ffill().bfill()\n",
    "print(df_beach.isna().sum())\n",
    "\n",
    "\n",
    "\n",
    "display(\"# Outlier Detection\")\n",
    "\n",
    "# Identify outliers using percentile technique\n",
    "\n",
    "outliers = {}\n",
    "\n",
    "for col in df_beach.select_dtypes(include = 'number').columns:\n",
    "    lower_bound = df_beach[col].quantile(0.001)\n",
    "    upper_bound = df_beach[col].quantile(0.999)\n",
    "    outliers[col] = df_beach[(df_beach[col] < lower_bound) | (df_beach[col] > upper_bound)][col]\n",
    "\n",
    "\n",
    "outlier_summary = pd.DataFrame({\n",
    "    \"column_name\": list(outliers.keys()),\n",
    "    \"outlier_count\": [len(vals) for vals in outliers.values()]\n",
    "})\n",
    "\n",
    "display(outlier_summary)\n",
    "\n",
    "outlier_indices = set()\n",
    "\n",
    "for col in df_beach.select_dtypes(include='number').columns:\n",
    "    lower_bound = df_beach[col].quantile(0.001)\n",
    "    upper_bound = df_beach[col].quantile(0.999)\n",
    "    \n",
    "    # find indices of outliers for this column\n",
    "    col_outliers = df_beach[(df_beach[col] < lower_bound) | (df_beach[col] > upper_bound)].index\n",
    "    \n",
    "    outlier_indices.update(col_outliers)\n",
    "\n",
    "df_beach_clean = df_beach.drop(index=outlier_indices)\n",
    "\n",
    "total_rows = len(df_beach)\n",
    "\n",
    "outlier_summary = pd.DataFrame({\n",
    "    \"column_name\": list(outliers.keys()),\n",
    "    \"outlier_count\": [len(v) for v in outliers.values()]\n",
    "})\n",
    "\n",
    "# Keep only columns with actual outliers\n",
    "outlier_summary = outlier_summary[outlier_summary[\"outlier_count\"] > 0]\n",
    "\n",
    "outlier_summary = outlier_summary.set_index(\"column_name\")\n",
    "\n",
    "outlier_summary[\"description\"] = (\n",
    "    \"- \" + outlier_summary.index\n",
    "    + \": \" + outlier_summary[\"outlier_count\"].astype(str)\n",
    "    + \" outliers detected \"\n",
    ")\n",
    "\n",
    "outlier_indices = set()\n",
    "\n",
    "for col, series in outliers.items():\n",
    "    outlier_indices.update(series.index)\n",
    "\n",
    "rows_removed = len(outlier_indices)\n",
    "\n",
    "outlier_report = (\n",
    "    \"Outlier Handling:\\n\"\n",
    "    f\"Detection method: Percentile-based thresholds (0.1-99.9th percentiles)\\n\"\n",
    "    f\"Columns with outliers: {', '.join(outlier_summary.index)}\\n\"\n",
    "    f\"Method used: Removed entire rows containing outliers\\n\"\n",
    "    f\"Number of outliers handled (rows removed): {rows_removed}\\n\\n\"\n",
    "    + \"\\n\".join(outlier_summary[\"description\"])\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Original rows:\", df_beach.shape[0])\n",
    "print(\"Rows removed:\", len(outlier_indices))\n",
    "print(\"Cleaned rows:\", df_beach_clean.shape[0])\n",
    "\n",
    "df_beach_clean['Measurement Timestamp'] = pd.to_datetime(df_beach_clean['Measurement Timestamp'])\n",
    "col_summary_clean = df_beach_clean.dtypes.to_frame(name = \"dtype\")\n",
    "print(col_summary_clean)\n",
    "\n",
    "# Check for duplicate rows\n",
    "display(\"# Duplicate Detection\")\n",
    "\n",
    "# Check for completely duplicate rows\n",
    "n_duplicates = df_beach_clean.duplicated().sum()\n",
    "display(f\"**Completely duplicate rows:** {n_duplicates:,}\")\n",
    "\n",
    "\n",
    "summary_clean = pd.DataFrame({\n",
    "    \"column_name\": df_beach_clean.columns,\n",
    "    \"mean\": df_beach_clean.mean(numeric_only=True).reindex(df_beach_clean.columns),\n",
    "    \"std\": df_beach_clean.std(numeric_only=True).reindex(df_beach_clean.columns),\n",
    "    \"min\": df_beach_clean.min(numeric_only=True).reindex(df_beach_clean.columns),\n",
    "    \"max\": df_beach_clean.max(numeric_only=True).reindex(df_beach_clean.columns),\n",
    "    \"missing_count\": df_beach_clean.isna().sum()\n",
    "})\n",
    "\n",
    "df_beach_clean.to_csv(\"output/q2_cleaned_data.csv\", index=False)\n",
    "\n",
    "missing = df_beach.isnull().sum()\n",
    "missing_pct = (missing / len(df_beach)) *100\n",
    "missing_before = pd.DataFrame({\n",
    "    'Missing Count' : missing, \n",
    "    'Missing %': missing_pct.round(2)\n",
    "})\n",
    "\n",
    "def make_description(row):\n",
    "    return (\n",
    "        f\"- {row.name}: {int(row['Missing Count'])} missing values ({row['Missing %']:.1f}%)\\n\"\n",
    "        f\"  Method: Forward-fill (time series appropriate)\\n\"\n",
    "        f\"  Result: All missing values filled\"\n",
    "    )\n",
    "\n",
    "missing_df[\"description\"] = missing_df.apply(make_description, axis=1)\n",
    "\n",
    "\n",
    "with open(\"output/q2_cleaning_report.txt\", \"w\") as f:\n",
    "    f.write(\"DATA CLEANING REPORT \\n ========== \\n\")\n",
    "    f.write(f\"Rows before cleaning: {df_beach.shape[0]} \\n\")\n",
    "    f.write(f\"Missing Data Handling: \\n\")\n",
    "    for text in missing_df[\"description\"]:\n",
    "        f.write(text + \"\\n\\n\")\n",
    "    f.write(outlier_report)\n",
    "    f.write(f\"\\n Duplicates removed: {n_duplicates:,} \\n\")\n",
    "    f.write(f\"Measurement Timestamp: Converted to datetime64[ns]\\n\")\n",
    "    f.write(f\"Rows after cleaning: {df_beach_clean.shape[0]} \\n\")\n",
    "\n",
    "with open(\"output/q2_rows_cleaned.txt\", \"w\") as f:\n",
    "    f.write(f\"{df_beach_clean.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
